{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (0.27.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from huggingface_hub) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.12.14)\n",
      "Requirement already satisfied: datasets in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from datasets) (3.11.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from datasets) (0.27.0)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/instructmol/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle \n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from argparse import Namespace\n",
    "from pathlib import Path\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "\n",
    "# For Graph Encoding\n",
    "from torch_geometric.data import Data as PyGData\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "\n",
    "import pickle\n",
    "from datasets import load_from_disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded to: /Users/smsultanmahmudrahat/Downloads/open_source/code/train.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "\n",
    "# Get the token from the environment variable\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "# Set repository details\n",
    "repo_id = \"OpenMol/PubChemSFT\"  # Repository ID\n",
    "filename = \"train.pkl\"          # Path to the file in the repository\n",
    "\n",
    "# Optional: Authenticate if the repository is private\n",
    "from huggingface_hub import login\n",
    "login(token=hf_token)  # Replace with your actual token\n",
    "local_dir = \"/Users/smsultanmahmudrahat/Downloads/open_source/code\"\n",
    "\n",
    "# Download the file\n",
    "try:\n",
    "    hf_file_path = hf_hub_download(repo_id=repo_id, filename=filename, repo_type=\"dataset\", local_dir= local_dir)\n",
    "    print(f\"File downloaded to: {hf_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qc/8812nyc533x05df3fh9jggnm0000gn/T/ipykernel_14589/1052652557.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(file_path, map_location=torch.device('cpu'))\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Get the token from the environment variable\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "# Repository and file details\n",
    "repo_id = \"chao1224/MoleculeSTM\"  # Repository name\n",
    "filename = \"demo/demo_checkpoints_SMILES/molecule_model_final.pth\"  # Path to the file in the repo\n",
    "\n",
    "# Optional: Authenticate if the repository is private\n",
    "from huggingface_hub import login\n",
    "login(token=hf_token)  \n",
    "local_dir = \"/Users/smsultanmahmudrahat/Downloads/open_source/code\"\n",
    "\n",
    "\n",
    "# Download file to memory\n",
    "file_path = hf_hub_download(repo_id=repo_id, filename=filename, repo_type=\"model\", local_dir= local_dir)\n",
    "\n",
    "# Load the PyTorch model directly from the file\n",
    "import torch\n",
    "# if GPU is available\n",
    "# model_state_dict = torch.load(file_path) \n",
    "model_state_dict = torch.load(file_path, map_location=torch.device('cpu'))\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['pos_emb', 'emb.weight', 'encoder.layers.0.self_attn.query_key_value.weight', 'encoder.layers.0.self_attn.query_key_value.bias', 'encoder.layers.0.self_attn.q_proj.weight', 'encoder.layers.0.self_attn.q_proj.bias', 'encoder.layers.0.self_attn.key_value.weight', 'encoder.layers.0.self_attn.key_value.bias', 'encoder.layers.0.self_attn.out_proj.weight', 'encoder.layers.0.self_attn.out_proj.bias', 'encoder.layers.0.self_attn_layer_norm.weight', 'encoder.layers.0.self_attn_layer_norm.bias', 'encoder.layers.0.fc1.weight', 'encoder.layers.0.fc1.bias', 'encoder.layers.0.fc2.weight', 'encoder.layers.0.fc2.bias', 'encoder.layers.0.final_layer_norm.weight', 'encoder.layers.0.final_layer_norm.bias', 'encoder.layers.1.self_attn.query_key_value.weight', 'encoder.layers.1.self_attn.query_key_value.bias', 'encoder.layers.1.self_attn.q_proj.weight', 'encoder.layers.1.self_attn.q_proj.bias', 'encoder.layers.1.self_attn.key_value.weight', 'encoder.layers.1.self_attn.key_value.bias', 'encoder.layers.1.self_attn.out_proj.weight', 'encoder.layers.1.self_attn.out_proj.bias', 'encoder.layers.1.self_attn_layer_norm.weight', 'encoder.layers.1.self_attn_layer_norm.bias', 'encoder.layers.1.fc1.weight', 'encoder.layers.1.fc1.bias', 'encoder.layers.1.fc2.weight', 'encoder.layers.1.fc2.bias', 'encoder.layers.1.final_layer_norm.weight', 'encoder.layers.1.final_layer_norm.bias', 'encoder.layers.2.self_attn.query_key_value.weight', 'encoder.layers.2.self_attn.query_key_value.bias', 'encoder.layers.2.self_attn.q_proj.weight', 'encoder.layers.2.self_attn.q_proj.bias', 'encoder.layers.2.self_attn.key_value.weight', 'encoder.layers.2.self_attn.key_value.bias', 'encoder.layers.2.self_attn.out_proj.weight', 'encoder.layers.2.self_attn.out_proj.bias', 'encoder.layers.2.self_attn_layer_norm.weight', 'encoder.layers.2.self_attn_layer_norm.bias', 'encoder.layers.2.fc1.weight', 'encoder.layers.2.fc1.bias', 'encoder.layers.2.fc2.weight', 'encoder.layers.2.fc2.bias', 'encoder.layers.2.final_layer_norm.weight', 'encoder.layers.2.final_layer_norm.bias', 'encoder.layers.3.self_attn.query_key_value.weight', 'encoder.layers.3.self_attn.query_key_value.bias', 'encoder.layers.3.self_attn.q_proj.weight', 'encoder.layers.3.self_attn.q_proj.bias', 'encoder.layers.3.self_attn.key_value.weight', 'encoder.layers.3.self_attn.key_value.bias', 'encoder.layers.3.self_attn.out_proj.weight', 'encoder.layers.3.self_attn.out_proj.bias', 'encoder.layers.3.self_attn_layer_norm.weight', 'encoder.layers.3.self_attn_layer_norm.bias', 'encoder.layers.3.fc1.weight', 'encoder.layers.3.fc1.bias', 'encoder.layers.3.fc2.weight', 'encoder.layers.3.fc2.bias', 'encoder.layers.3.final_layer_norm.weight', 'encoder.layers.3.final_layer_norm.bias', 'encoder.norm.weight', 'encoder.norm.bias', 'decoder.layers.0.self_attn.query_key_value.weight', 'decoder.layers.0.self_attn.query_key_value.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.key_value.weight', 'decoder.layers.0.self_attn.key_value.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn.query_key_value.weight', 'decoder.layers.0.encoder_attn.query_key_value.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.key_value.weight', 'decoder.layers.0.encoder_attn.key_value.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.query_key_value.weight', 'decoder.layers.1.self_attn.query_key_value.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.key_value.weight', 'decoder.layers.1.self_attn.key_value.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn.query_key_value.weight', 'decoder.layers.1.encoder_attn.query_key_value.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.key_value.weight', 'decoder.layers.1.encoder_attn.key_value.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.query_key_value.weight', 'decoder.layers.2.self_attn.query_key_value.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.key_value.weight', 'decoder.layers.2.self_attn.key_value.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.encoder_attn.query_key_value.weight', 'decoder.layers.2.encoder_attn.query_key_value.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.key_value.weight', 'decoder.layers.2.encoder_attn.key_value.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.query_key_value.weight', 'decoder.layers.3.self_attn.query_key_value.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.key_value.weight', 'decoder.layers.3.self_attn.key_value.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.encoder_attn.query_key_value.weight', 'decoder.layers.3.encoder_attn.query_key_value.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.key_value.weight', 'decoder.layers.3.encoder_attn.key_value.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.norm.weight', 'decoder.norm.bias', 'token_fc.weight', 'token_fc.bias'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.OrderedDict"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pickle\n",
    "from torch_geometric.data import Data as PyGData\n",
    "from datasets import load_from_disk\n",
    "import torch\n",
    "\n",
    "class GraphTextDataset(Dataset):\n",
    "    def __init__(self, hf_dataset):\n",
    "        # Load graph data\n",
    "        with open(hf_dataset, \"rb\") as f:\n",
    "            self.graph_data = pickle.load(f)\n",
    "\n",
    "        # Load text data from HuggingFace's dataset\n",
    "        # self.text_data = load_from_disk(graph_path)\n",
    "        print(f\"Length of graph_data: {len(self.graph_data)}\")\n",
    "\n",
    "        # Optionally, ensure lengths match\n",
    "        # assert len(self.graph_data) == len(self.text_data), \"Graph and text data lengths do not match!\"\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the length of the dataset\n",
    "        return len(self.graph_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Fetch graph data\n",
    "        item = self.graph_data[idx]\n",
    "        gdict = item[\"graph\"]\n",
    "\n",
    "        edge_index = torch.tensor(gdict[\"edge_index\"], dtype=torch.long)\n",
    "        node_feat = torch.tensor(gdict[\"node_feat\"], dtype=torch.long)\n",
    "\n",
    "        # Handle edge attributes\n",
    "        edge_attr = gdict.get(\"edge_attr\", None)\n",
    "        if edge_attr is not None:\n",
    "            edge_attr = torch.tensor(edge_attr, dtype=torch.long)\n",
    "        else:\n",
    "            num_edges = edge_index.size(1)\n",
    "            edge_attr = torch.zeros((num_edges, 2), dtype=torch.long)\n",
    "\n",
    "        # Batch information (dummy for now)\n",
    "        batch = torch.zeros((node_feat.size(0),), dtype=torch.long)\n",
    "\n",
    "        # Create PyGData object\n",
    "        pyg_graph = PyGData(\n",
    "            x=node_feat,\n",
    "            edge_attr=edge_attr,\n",
    "            edge_index=edge_index,\n",
    "            batch=batch,\n",
    "        )\n",
    "\n",
    "        # Fetch text data\n",
    "        text = self.graph_data[idx][\"answer\"]\n",
    "\n",
    "        return pyg_graph, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of graph_data: 264391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "264391"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = GraphTextDataset(hf_file_path)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    model_name_or_path=\"lmsys/vicuna-7b-v1.3\",\n",
    "    # graph_data_path= graph_path,  # Change to your dataset path\n",
    "    hf_data_path = hf_file_path,\n",
    "    output_dir=\"/Users/smsultanmahmudrahat/Downloads/open_source/code\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    learning_rate=2e-3,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "device = args.device\n",
    "\n",
    "########################################\n",
    "# Replace with correct MoleculeSTM parameters as needed\n",
    "########################################\n",
    "NUM_LAYER = 4       # Number of GNN layers (adjust if known)\n",
    "EMB_DIM = 300        # Embedding dimension used by MoleculeSTM (adjust if known)\n",
    "JK = \"last\"          # The JK-connection mode used (adjust if known)\n",
    "GRAPH_POOLING = \"mean\"  # Pooling mode: sum/mean/max (adjust if known)\n",
    "# check smile-> grpahPath\n",
    "INIT_CHECKPOINT = Path(\"/Users/smsultanmahmudrahat/Downloads/open_source/code/pickel_files/molecule_model.pth\") # Path to molecule_model.pth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import (MessagePassing, global_add_pool,\n",
    "                                global_max_pool, global_mean_pool)\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "from torch_geometric.utils import add_self_loops, softmax, degree\n",
    "from torch_scatter import scatter_add\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "class GINConv(MessagePassing):\n",
    "    def __init__(self, emb_dim, aggr=\"add\"):\n",
    "        '''\n",
    "            emb_dim (int): node embedding dimensionality\n",
    "        '''\n",
    "        super(GINConv, self).__init__(aggr=aggr)\n",
    "\n",
    "        self.mlp = torch.nn.Sequential(torch.nn.Linear(emb_dim, 2*emb_dim), torch.nn.BatchNorm1d(2*emb_dim), torch.nn.ReLU(), torch.nn.Linear(2*emb_dim, emb_dim))\n",
    "        self.eps = torch.nn.Parameter(torch.Tensor([0]))\n",
    "\n",
    "        self.bond_encoder = BondEncoder(emb_dim = emb_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        edge_embedding = self.bond_encoder(edge_attr)\n",
    "        # WARN: some weird thing happend if excute in bfloat16, so we force to cast to float32\n",
    "        dtype = x.dtype\n",
    "        inter = (1 + self.eps) *x + self.propagate(edge_index, x=x, edge_attr=edge_embedding)\n",
    "        if dtype == torch.bfloat16:\n",
    "            inter = inter.float()\n",
    "            out = self.mlp.float()(inter)\n",
    "            out = out.to(dtype)\n",
    "        else:\n",
    "            out = self.mlp(inter)\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        return F.relu(x_j + edge_attr)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out\n",
    "\n",
    "\n",
    "\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, emb_dim, aggr=\"add\"):\n",
    "        super(GCNConv, self).__init__(aggr=aggr)\n",
    "\n",
    "        self.linear = torch.nn.Linear(emb_dim, emb_dim)\n",
    "        self.root_emb = torch.nn.Embedding(1, emb_dim)\n",
    "        self.bond_encoder = BondEncoder(emb_dim = emb_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.linear(x)\n",
    "        edge_embedding = self.bond_encoder(edge_attr)\n",
    "\n",
    "        row, col = edge_index\n",
    "\n",
    "        #edge_weight = torch.ones((edge_index.size(1), ), device=edge_index.device)\n",
    "        deg = degree(row, x.size(0), dtype = x.dtype) + 1\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        return self.propagate(edge_index, x=x, edge_attr = edge_embedding, norm=norm) + F.relu(x + self.root_emb.weight) * 1./deg.view(-1,1)\n",
    "\n",
    "    def message(self, x_j, edge_attr, norm):\n",
    "        return norm.view(-1, 1) * F.relu(x_j + edge_attr)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out\n",
    "\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, num_layer, emb_dim, JK=\"last\", drop_ratio=0., gnn_type=\"gin\"):\n",
    "\n",
    "        if num_layer < 2:\n",
    "            raise ValueError(\"Number of GNN layers must be greater than 1.\")\n",
    "\n",
    "        super(GNN, self).__init__()\n",
    "        self.drop_ratio = drop_ratio\n",
    "        self.num_layer = num_layer\n",
    "        self.JK = JK\n",
    "\n",
    "        self.atom_encoder = AtomEncoder(emb_dim)\n",
    "\n",
    "        ###List of MLPs\n",
    "        self.gnns = nn.ModuleList()\n",
    "        for layer in range(num_layer):\n",
    "            if gnn_type == \"gin\":\n",
    "                self.gnns.append(GINConv(emb_dim, aggr=\"add\"))\n",
    "            elif gnn_type == \"gcn\":\n",
    "                self.gnns.append(GCNConv(emb_dim))\n",
    "\n",
    "        ###List of batchnorms\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        for layer in range(num_layer):\n",
    "            self.batch_norms.append(nn.BatchNorm1d(emb_dim))\n",
    "\n",
    "    # def forward(self, x, edge_index, edge_attr):\n",
    "    def forward(self, *argv):\n",
    "        if len(argv) == 3:\n",
    "            x, edge_index, edge_attr = argv[0], argv[1], argv[2]\n",
    "        elif len(argv) == 1:\n",
    "            data = argv[0]\n",
    "            x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        else:\n",
    "            raise ValueError(\"unmatched number of arguments.\")\n",
    "\n",
    "        x = self.atom_encoder(x)\n",
    "\n",
    "        h_list = [x]\n",
    "        for layer in range(self.num_layer):\n",
    "            h = self.gnns[layer](h_list[layer], edge_index, edge_attr)\n",
    "            h = self.batch_norms[layer](h)\n",
    "            # h = F.dropout(F.relu(h), self.drop_ratio, training = self.training)\n",
    "            if layer == self.num_layer - 1:\n",
    "                # remove relu for the last layer\n",
    "                h = F.dropout(h, self.drop_ratio, training=self.training)\n",
    "            else:\n",
    "                h = F.dropout(F.relu(h), self.drop_ratio, training=self.training)\n",
    "            h_list.append(h)\n",
    "\n",
    "        ### Different implementations of Jk-concat\n",
    "        if self.JK == \"concat\":\n",
    "            node_representation = torch.cat(h_list, dim=1)\n",
    "        elif self.JK == \"last\":\n",
    "            node_representation = h_list[-1]\n",
    "        elif self.JK == \"max\":\n",
    "            h_list = [h.unsqueeze_(0) for h in h_list]\n",
    "            node_representation = torch.max(torch.cat(h_list, dim=0), dim=0)[0]\n",
    "        elif self.JK == \"sum\":\n",
    "            h_list = [h.unsqueeze_(0) for h in h_list]\n",
    "            node_representation = torch.sum(torch.cat(h_list, dim=0), dim=0)[0]\n",
    "        else:\n",
    "            raise ValueError(\"not implemented.\")\n",
    "        return node_representation\n",
    "\n",
    "\n",
    "class GNN_graphpred(nn.Module):\n",
    "    \"\"\"\n",
    "    Extension of GIN to incorporate edge information by concatenation.\n",
    "\n",
    "    Args:\n",
    "        num_layer (int): the number of GNN layers\n",
    "        arg.emb_dim (int): dimensionality of embeddings\n",
    "        num_tasks (int): number of tasks in multi-task learning scenario\n",
    "        JK (str): last, concat, max or sum.\n",
    "        graph_pooling (str): sum, mean, max, attention, set2set\n",
    "\n",
    "    See https://arxiv.org/abs/1810.00826\n",
    "    JK-net: https://arxiv.org/abs/1806.03536 \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        emb_dim,  \n",
    "        graph_pooling, \n",
    "        projection_dim:int=None,\n",
    "        molecule_node_model=None,\n",
    "        init_checkpoint=None,\n",
    "    ):\n",
    "        super(GNN_graphpred, self).__init__()\n",
    "\n",
    "        self.molecule_node_model = molecule_node_model\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "        # Different kind of graph pooling\n",
    "        if graph_pooling == \"sum\":\n",
    "            self.pool = global_add_pool\n",
    "        elif graph_pooling == \"mean\":\n",
    "            self.pool = global_mean_pool\n",
    "        elif graph_pooling == \"max\":\n",
    "            self.pool = global_max_pool\n",
    "        else:\n",
    "            raise ValueError(\"Invalid graph pooling type.\")\n",
    "        \n",
    "        if projection_dim is not None:\n",
    "            self.projector = nn.Linear(emb_dim, projection_dim)\n",
    "            self.output_dim = projection_dim\n",
    "        else:\n",
    "            self.projector = None\n",
    "            self.output_dim = emb_dim\n",
    "        \n",
    "        if init_checkpoint is not None:\n",
    "            self._load_state_dict(init_checkpoint, strict=False)\n",
    "\n",
    "    def forward(self, *argv):\n",
    "        if len(argv) == 4:\n",
    "            x, edge_index, edge_attr, batch = argv[0], argv[1], argv[2], argv[3]\n",
    "        elif len(argv) == 1:\n",
    "            data = argv[0]\n",
    "            x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        else:\n",
    "            raise ValueError(\"unmatched number of arguments.\")\n",
    "\n",
    "        node_representation = self.molecule_node_model(x, edge_index, edge_attr)\n",
    "        graph_representation = self.pool(node_representation, batch)\n",
    "        return graph_representation, node_representation\n",
    "    \n",
    "    def encode_mol(self, mol, proj=False, return_node_feats=False, eval=True):\n",
    "        if eval:\n",
    "            self.molecule_node_model.eval() # hard code: set to eval mode\n",
    "            with torch.no_grad():\n",
    "                h_graph, h_node = self.forward(mol)\n",
    "        else:\n",
    "            self.molecule_node_model.train() # set to train mode\n",
    "            h_graph, h_node = self.forward(mol)\n",
    "        if proj and self.projector is not None:\n",
    "            h_graph = self.projector(h_graph)\n",
    "            h_node = self.projector(h_node)\n",
    "        if return_node_feats:\n",
    "            return h_graph, h_node\n",
    "        else:\n",
    "            return h_graph\n",
    "    \n",
    "    # def _load_state_dict(self, model_file, strict=False):\n",
    "    #     print(\"Loading from {} ...\".format(model_file))\n",
    "    #     state_dict = torch.load(model_file, map_location=torch.device('cpu'))\n",
    "    #     self.load_state_dict(state_dict, strict=strict)\n",
    "    #     return\n",
    "    \n",
    "    def _load_state_dict(self, model_file, strict=False):\n",
    "        print(f\"Loading from {model_file} ...\")\n",
    "        state_dict = torch.load(model_file, map_location=torch.device('cpu'))\n",
    "        incompatible_keys = self.load_state_dict(state_dict, strict=strict)\n",
    "        print(f\"Missing keys: {incompatible_keys.missing_keys}\")\n",
    "        print(f\"Unexpected keys: {incompatible_keys.unexpected_keys}\")\n",
    "        return\n",
    "    \n",
    "    @property\n",
    "    def dummy_feature(self):\n",
    "        return self.zeros(1, self.hidden_size, device=self.device, dtype=self.dtype)\n",
    "    \n",
    "    @property\n",
    "    def hidden_size(self):\n",
    "        return self.output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 20.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hidden size of the model is: 4096\n",
      "Loading from /Users/smsultanmahmudrahat/Downloads/open_source/code/pickel_files/molecule_model.pth ...\n",
      "Missing keys: ['molecule_node_model.atom_encoder.atom_embedding_list.0.weight', 'molecule_node_model.atom_encoder.atom_embedding_list.1.weight', 'molecule_node_model.atom_encoder.atom_embedding_list.2.weight', 'molecule_node_model.atom_encoder.atom_embedding_list.3.weight', 'molecule_node_model.atom_encoder.atom_embedding_list.4.weight', 'molecule_node_model.atom_encoder.atom_embedding_list.5.weight', 'molecule_node_model.atom_encoder.atom_embedding_list.6.weight', 'molecule_node_model.atom_encoder.atom_embedding_list.7.weight', 'molecule_node_model.atom_encoder.atom_embedding_list.8.weight', 'molecule_node_model.gnns.0.eps', 'molecule_node_model.gnns.0.mlp.0.weight', 'molecule_node_model.gnns.0.mlp.0.bias', 'molecule_node_model.gnns.0.mlp.1.weight', 'molecule_node_model.gnns.0.mlp.1.bias', 'molecule_node_model.gnns.0.mlp.1.running_mean', 'molecule_node_model.gnns.0.mlp.1.running_var', 'molecule_node_model.gnns.0.mlp.3.weight', 'molecule_node_model.gnns.0.mlp.3.bias', 'molecule_node_model.gnns.0.bond_encoder.bond_embedding_list.0.weight', 'molecule_node_model.gnns.0.bond_encoder.bond_embedding_list.1.weight', 'molecule_node_model.gnns.0.bond_encoder.bond_embedding_list.2.weight', 'molecule_node_model.gnns.1.eps', 'molecule_node_model.gnns.1.mlp.0.weight', 'molecule_node_model.gnns.1.mlp.0.bias', 'molecule_node_model.gnns.1.mlp.1.weight', 'molecule_node_model.gnns.1.mlp.1.bias', 'molecule_node_model.gnns.1.mlp.1.running_mean', 'molecule_node_model.gnns.1.mlp.1.running_var', 'molecule_node_model.gnns.1.mlp.3.weight', 'molecule_node_model.gnns.1.mlp.3.bias', 'molecule_node_model.gnns.1.bond_encoder.bond_embedding_list.0.weight', 'molecule_node_model.gnns.1.bond_encoder.bond_embedding_list.1.weight', 'molecule_node_model.gnns.1.bond_encoder.bond_embedding_list.2.weight', 'molecule_node_model.gnns.2.eps', 'molecule_node_model.gnns.2.mlp.0.weight', 'molecule_node_model.gnns.2.mlp.0.bias', 'molecule_node_model.gnns.2.mlp.1.weight', 'molecule_node_model.gnns.2.mlp.1.bias', 'molecule_node_model.gnns.2.mlp.1.running_mean', 'molecule_node_model.gnns.2.mlp.1.running_var', 'molecule_node_model.gnns.2.mlp.3.weight', 'molecule_node_model.gnns.2.mlp.3.bias', 'molecule_node_model.gnns.2.bond_encoder.bond_embedding_list.0.weight', 'molecule_node_model.gnns.2.bond_encoder.bond_embedding_list.1.weight', 'molecule_node_model.gnns.2.bond_encoder.bond_embedding_list.2.weight', 'molecule_node_model.gnns.3.eps', 'molecule_node_model.gnns.3.mlp.0.weight', 'molecule_node_model.gnns.3.mlp.0.bias', 'molecule_node_model.gnns.3.mlp.1.weight', 'molecule_node_model.gnns.3.mlp.1.bias', 'molecule_node_model.gnns.3.mlp.1.running_mean', 'molecule_node_model.gnns.3.mlp.1.running_var', 'molecule_node_model.gnns.3.mlp.3.weight', 'molecule_node_model.gnns.3.mlp.3.bias', 'molecule_node_model.gnns.3.bond_encoder.bond_embedding_list.0.weight', 'molecule_node_model.gnns.3.bond_encoder.bond_embedding_list.1.weight', 'molecule_node_model.gnns.3.bond_encoder.bond_embedding_list.2.weight', 'molecule_node_model.batch_norms.0.weight', 'molecule_node_model.batch_norms.0.bias', 'molecule_node_model.batch_norms.0.running_mean', 'molecule_node_model.batch_norms.0.running_var', 'molecule_node_model.batch_norms.1.weight', 'molecule_node_model.batch_norms.1.bias', 'molecule_node_model.batch_norms.1.running_mean', 'molecule_node_model.batch_norms.1.running_var', 'molecule_node_model.batch_norms.2.weight', 'molecule_node_model.batch_norms.2.bias', 'molecule_node_model.batch_norms.2.running_mean', 'molecule_node_model.batch_norms.2.running_var', 'molecule_node_model.batch_norms.3.weight', 'molecule_node_model.batch_norms.3.bias', 'molecule_node_model.batch_norms.3.running_mean', 'molecule_node_model.batch_norms.3.running_var']\n",
      "Unexpected keys: ['pos_emb', 'emb.weight', 'encoder.layers.0.self_attn.query_key_value.weight', 'encoder.layers.0.self_attn.query_key_value.bias', 'encoder.layers.0.self_attn.q_proj.weight', 'encoder.layers.0.self_attn.q_proj.bias', 'encoder.layers.0.self_attn.key_value.weight', 'encoder.layers.0.self_attn.key_value.bias', 'encoder.layers.0.self_attn.out_proj.weight', 'encoder.layers.0.self_attn.out_proj.bias', 'encoder.layers.0.self_attn_layer_norm.weight', 'encoder.layers.0.self_attn_layer_norm.bias', 'encoder.layers.0.fc1.weight', 'encoder.layers.0.fc1.bias', 'encoder.layers.0.fc2.weight', 'encoder.layers.0.fc2.bias', 'encoder.layers.0.final_layer_norm.weight', 'encoder.layers.0.final_layer_norm.bias', 'encoder.layers.1.self_attn.query_key_value.weight', 'encoder.layers.1.self_attn.query_key_value.bias', 'encoder.layers.1.self_attn.q_proj.weight', 'encoder.layers.1.self_attn.q_proj.bias', 'encoder.layers.1.self_attn.key_value.weight', 'encoder.layers.1.self_attn.key_value.bias', 'encoder.layers.1.self_attn.out_proj.weight', 'encoder.layers.1.self_attn.out_proj.bias', 'encoder.layers.1.self_attn_layer_norm.weight', 'encoder.layers.1.self_attn_layer_norm.bias', 'encoder.layers.1.fc1.weight', 'encoder.layers.1.fc1.bias', 'encoder.layers.1.fc2.weight', 'encoder.layers.1.fc2.bias', 'encoder.layers.1.final_layer_norm.weight', 'encoder.layers.1.final_layer_norm.bias', 'encoder.layers.2.self_attn.query_key_value.weight', 'encoder.layers.2.self_attn.query_key_value.bias', 'encoder.layers.2.self_attn.q_proj.weight', 'encoder.layers.2.self_attn.q_proj.bias', 'encoder.layers.2.self_attn.key_value.weight', 'encoder.layers.2.self_attn.key_value.bias', 'encoder.layers.2.self_attn.out_proj.weight', 'encoder.layers.2.self_attn.out_proj.bias', 'encoder.layers.2.self_attn_layer_norm.weight', 'encoder.layers.2.self_attn_layer_norm.bias', 'encoder.layers.2.fc1.weight', 'encoder.layers.2.fc1.bias', 'encoder.layers.2.fc2.weight', 'encoder.layers.2.fc2.bias', 'encoder.layers.2.final_layer_norm.weight', 'encoder.layers.2.final_layer_norm.bias', 'encoder.layers.3.self_attn.query_key_value.weight', 'encoder.layers.3.self_attn.query_key_value.bias', 'encoder.layers.3.self_attn.q_proj.weight', 'encoder.layers.3.self_attn.q_proj.bias', 'encoder.layers.3.self_attn.key_value.weight', 'encoder.layers.3.self_attn.key_value.bias', 'encoder.layers.3.self_attn.out_proj.weight', 'encoder.layers.3.self_attn.out_proj.bias', 'encoder.layers.3.self_attn_layer_norm.weight', 'encoder.layers.3.self_attn_layer_norm.bias', 'encoder.layers.3.fc1.weight', 'encoder.layers.3.fc1.bias', 'encoder.layers.3.fc2.weight', 'encoder.layers.3.fc2.bias', 'encoder.layers.3.final_layer_norm.weight', 'encoder.layers.3.final_layer_norm.bias', 'encoder.norm.weight', 'encoder.norm.bias', 'decoder.layers.0.self_attn.query_key_value.weight', 'decoder.layers.0.self_attn.query_key_value.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.key_value.weight', 'decoder.layers.0.self_attn.key_value.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn.query_key_value.weight', 'decoder.layers.0.encoder_attn.query_key_value.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.key_value.weight', 'decoder.layers.0.encoder_attn.key_value.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.query_key_value.weight', 'decoder.layers.1.self_attn.query_key_value.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.key_value.weight', 'decoder.layers.1.self_attn.key_value.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn.query_key_value.weight', 'decoder.layers.1.encoder_attn.query_key_value.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.key_value.weight', 'decoder.layers.1.encoder_attn.key_value.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.query_key_value.weight', 'decoder.layers.2.self_attn.query_key_value.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.key_value.weight', 'decoder.layers.2.self_attn.key_value.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.encoder_attn.query_key_value.weight', 'decoder.layers.2.encoder_attn.query_key_value.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.key_value.weight', 'decoder.layers.2.encoder_attn.key_value.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.query_key_value.weight', 'decoder.layers.3.self_attn.query_key_value.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.key_value.weight', 'decoder.layers.3.self_attn.key_value.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.encoder_attn.query_key_value.weight', 'decoder.layers.3.encoder_attn.query_key_value.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.key_value.weight', 'decoder.layers.3.encoder_attn.key_value.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.norm.weight', 'decoder.norm.bias', 'token_fc.weight', 'token_fc.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/qc/8812nyc533x05df3fh9jggnm0000gn/T/ipykernel_14589/1224073858.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_file, map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GNN_graphpred(\n",
       "  (molecule_node_model): GNN(\n",
       "    (atom_encoder): AtomEncoder(\n",
       "      (atom_embedding_list): ModuleList(\n",
       "        (0): Embedding(119, 300)\n",
       "        (1): Embedding(5, 300)\n",
       "        (2-3): 2 x Embedding(12, 300)\n",
       "        (4): Embedding(10, 300)\n",
       "        (5-6): 2 x Embedding(6, 300)\n",
       "        (7-8): 2 x Embedding(2, 300)\n",
       "      )\n",
       "    )\n",
       "    (gnns): ModuleList(\n",
       "      (0-3): 4 x GINConv()\n",
       "    )\n",
       "    (batch_norms): ModuleList(\n",
       "      (0-3): 4 x BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model_name_or_path = \"lmsys/vicuna-7b-v1.3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=False)\n",
    "llm_model = AutoModel.from_pretrained(model_name_or_path) \n",
    "\n",
    "# now we need to freeze the llm model \n",
    "llm_model.eval().requires_grad_(False)\n",
    "\n",
    "llm_hidden = llm_model.config.hidden_size\n",
    "print(f\"The hidden size of the model is: {llm_hidden}\")\n",
    "\n",
    "# it will be used to predict next node \n",
    "# it processes molecules and produces graph embedding \n",
    "molecule_node_model = GNN(\n",
    "\tnum_layer= NUM_LAYER, emb_dim= EMB_DIM, JK= JK, drop_ratio = 0, gnn_type=\"gin\")\n",
    "\n",
    "# now predict the graph embedding because it will use pooling for it. \n",
    "# two GNN architecture is design independantly for better design flexibility. \n",
    "\n",
    "graph_encoder = GNN_graphpred(\n",
    "\temb_dim= EMB_DIM,\n",
    "\tgraph_pooling = \"mean\",\n",
    "\t# if we want to match it with the Text emb hidden layer, we could use it. \n",
    "\t# but we have used nn.Linear() for projecting the emb to better alignment. \n",
    "\t# so, we will not project anything.So, emb_dim and output er dimension same thakbe.\n",
    "\tprojection_dim = None,\n",
    "\t# node level pred k ei layer e integrate korbo.\n",
    "\tmolecule_node_model = molecule_node_model,\n",
    "\t# load the weights in same architecture\n",
    "\tinit_checkpoint = INIT_CHECKPOINT)\n",
    "\n",
    "graph_encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn (batch):\n",
    "\t# 1st element of the graph \n",
    "\tgraphs = [b[0] for b in batch]\n",
    "\t# 2nd element of the batch is texts \n",
    "\ttexts = [b[1] for b in batch]\n",
    "\treturn Batch.from_data_list(graphs), texts \n",
    "\n",
    "def alignment_loss(graph_emb, text_emb):\n",
    "\t\n",
    "\t# before cosine similarity both emb should be normalized \n",
    "\tgraph = F.normalize(graph_emb, p= 2, dim=-1)\n",
    "\ttext = F.normalize (text_emb,p=2, dim =-1)\n",
    "\t\n",
    "\t# similarity between graph and text \n",
    "\tsim = graph @ text.T \n",
    "\tbatch_size = sim.size(0)\n",
    "\t\n",
    "\ttarget = torch.arange(batch_size, dtype= torch.long, device= sim.device)\n",
    "\t\n",
    "\t# now find out the entropy or loss function for text and graph \n",
    "\t\n",
    "\tloss_g2t = F.cross_entropy(F.log_softmax(sim,dim= -1), target) \n",
    "\tloss_t2g = F.cross_entropy(F.log_softmax(sim.T,dim= -1), target)\n",
    "\t\n",
    "\tloss = (loss_g2t+loss_t2g)/2.0\n",
    "\t\n",
    "\treturn loss \n",
    "\n",
    "# now it will help \n",
    "data_loader = PyGDataLoader(\n",
    "\tdataset = dataset, \n",
    "\tbatch_size = 8, \n",
    "\tshuffle = True, collate_fn = collate_fn, num_workers=0)\n",
    "\n",
    "\n",
    "projector = nn.Linear(graph_encoder.output_dim, llm_hidden).to(device)\n",
    "# optimize it\n",
    "optimizer = torch.optim.Adam(params = projector.parameters(), lr= args.learning_rate, weight_decay= 0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embedding(text_list):\n",
    "    encoding = tokenizer(text_list, return_tensors = \"pt\", padding = True, truncation= True,max_length = 128)\n",
    "    # return of encoding is a dict. {\"input_ids\" :... ,\"attention_maskk\" : 1,0,1... }\n",
    "    token_id = encoding[\"input_ids\"]\n",
    "    attention_mask = encoding[\"attention_mask\"]\n",
    "    \n",
    "    # torch.no_grad() means no backprop, no weight update\n",
    "    # gradient update is important in training.\n",
    "    # but torch.no_grad() is used in inference cause\n",
    "    # no gradient update is needed in that stage. \n",
    "    # and that's important not to gradient update.\n",
    "    with torch.no_grad():\n",
    "        # we input token_ID as text as a token value like 12,23 etc. \n",
    "        # and attention_mask inside the model\n",
    "        # Input sequence: \"Hello, how are you?\" (length 5)\n",
    "        # Padded sequence: \"Hello, how are you? [PAD] [PAD]\" (length 7)\n",
    "        # [1, 1, 1, 1, 1, 0, 0] is the attention mask to padding. \n",
    "        # padding helps us to eliminate data leakage? NO! it prevents model not to calculate \n",
    "        # [PAD] token otherwise it will be used in query attention generation.\n",
    "\n",
    "        output = llm_model(token_id, attention_mask)\n",
    "        # shape of output is: [batch_size, seq_length, hidden_state]\n",
    "        \n",
    "        # [2,5,128] means 2 sentences and each sentences have 5 token and each token has 128 dim vector. \n",
    "        # mean(dim=1) we are geting one embedding for each sentences of token \n",
    "        # [batch_size, seq_length, hidden_state] converts into [batch_size, hidden_state] \n",
    "        text_emb = output.last_hidden_state.mean(dim= 1)\n",
    "    return text_emb\n",
    "\n",
    "#####################################\n",
    "# training method \n",
    "############################\n",
    "for epoch in range(args.num_train_epochs):\n",
    "    projector.train()\n",
    "    \n",
    "    for step, (batch_graph, text) in enumerate (data_loader):\n",
    "        \n",
    "        # all graphs are distributed to the devices\n",
    "        batch_graphs = batch_graph.to(device) \n",
    "\n",
    "        # print the size of the batch_graph.x \n",
    "        print(f\" Size of the batch_graph.x: {batch_graph.x.size()}\")\n",
    "        # number of total graph in a batch \n",
    "        # print(f\"Number of graphs in the batch: {batch_graph.num_graphs}\")\n",
    "        # we are making a graph_encoder so we are not update gradient for it. \n",
    "        # LLM and graph encoder will be assigned with their pretrained weight and they will be frozen \n",
    "        # during the training process. so we will not update the gradient of LLM and GNN. We will only \n",
    "        # update the model with projector.train() \n",
    "        with torch.no_grad():\n",
    "            # make a dummpy input so that we can text whether the \n",
    "            # graph archi is working or not. \n",
    "            # graph_emb, _ = graph_encoder(*[torch.zeros(1, dtypes= torch.long).to(device)])\n",
    "            \n",
    "            # if the dummy works, then we will generate actual graph_encoder \n",
    "            \n",
    "            graph_emb, _ = graph_encoder(batch_graph)\n",
    "            \n",
    "            \n",
    "        # now we will load LLM mode to generate text. we will not update their trainign weight \n",
    "        with torch.no_grad():\n",
    "            text_emb = get_text_embedding(text)\n",
    "\n",
    "        proj_g = projector(graph_emb)\n",
    "        \n",
    "        loss = alignment_loss(proj_g,text_emb)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print loss every few steps\n",
    "        \n",
    "        if step %10 == 0:\n",
    "            print(f\"Epoch {epoch}, Step {step}, Loss: {loss.item():.4f}\")\n",
    "            \n",
    "    \n",
    "    # save projector checkpoint each epoch\n",
    "    os.makedirs (args.output_dir, exist_ok=True)\n",
    "    torch.save(projector.state_dict(), os.path.join(args.output_dir, f\"projector_epoch{epoch}.pth\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instructmol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
